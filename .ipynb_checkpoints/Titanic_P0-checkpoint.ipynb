{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dae8e42",
   "metadata": {},
   "source": [
    "# 1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f697abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685bccf",
   "metadata": {},
   "source": [
    "# 2) Read in and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc7ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train and test CSV files\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c09367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                     Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                      891   891   \n",
       "unique          NaN         NaN         NaN                      891     2   \n",
       "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
       "freq            NaN         NaN         NaN                        1   577   \n",
       "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch  Ticket        Fare    Cabin  \\\n",
       "count   714.000000  891.000000  891.000000     891  891.000000      204   \n",
       "unique         NaN         NaN         NaN     681         NaN      147   \n",
       "top            NaN         NaN         NaN  347082         NaN  B96 B98   \n",
       "freq           NaN         NaN         NaN       7         NaN        4   \n",
       "mean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
       "std      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
       "min       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
       "25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
       "50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
       "75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
       "max      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the training data\n",
    "train.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b899c15",
   "metadata": {},
   "source": [
    "# 3) Data Analysis\n",
    "- We're going to consider the features in the dataset and how complete they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac85545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#get a list of the features within the dataset\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "081cc3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Barah, Mr. Hanna Assi</td>\n",
       "      <td>male</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2663</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Toomey, Miss. Ellen</td>\n",
       "      <td>female</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F.C.C. 13531</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350035</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain, Dr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244278</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                            Name     Sex  \\\n",
       "762          763         1       3           Barah, Mr. Hanna Assi    male   \n",
       "458          459         1       2             Toomey, Miss. Ellen  female   \n",
       "305          306         1       1  Allison, Master. Hudson Trevor    male   \n",
       "499          500         0       3              Svensson, Mr. Olof    male   \n",
       "398          399         0       2                Pain, Dr. Alfred    male   \n",
       "\n",
       "       Age  SibSp  Parch        Ticket      Fare    Cabin Embarked  \n",
       "762  20.00      0      0          2663    7.2292      NaN        C  \n",
       "458  50.00      0      0  F.C.C. 13531   10.5000      NaN        S  \n",
       "305   0.92      1      2        113781  151.5500  C22 C26        S  \n",
       "499  24.00      0      0        350035    7.7958      NaN        S  \n",
       "398  23.00      0      0        244278   10.5000      NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see a sample of the dataset to get an idea of the variables\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d34a85",
   "metadata": {},
   "source": [
    "#### Numerical Features: Age (Continuous), Fare (Continuous), SibSp (Discrete), Parch (Discrete)\n",
    "\n",
    "#### Categorical Features: Survived, Sex, Embarked, Pclass\n",
    "\n",
    "#### Alphanumeric Features: Ticket, Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0febd82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tType of data\n",
      "\n",
      "Train dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Verify the type of data\n",
    "print('\\t\\tType of data\\n')\n",
    "\n",
    "print(\"Train dataset\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see a summary of the training dataset\n",
    "train.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ebf48",
   "metadata": {},
   "source": [
    "Some Observations:\n",
    "There are a total of 891 passengers in our training set.\n",
    "The Age feature is missing approximately 19.8% of its values. I'm guessing that the Age feature is pretty important to survival, so we should probably attempt to fill these gaps.\n",
    "The Cabin feature is missing approximately 77.1% of its values. Since so much of the feature is missing, it would be hard to fill in the missing values. We'll probably drop these values from our dataset.\n",
    "The Embarked feature is missing 0.22% of its values, which should be relatively harmless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for any other unusable values\n",
    "print(pd.isnull(train).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb391a0e",
   "metadata": {},
   "source": [
    "Some Predictions:\n",
    "Sex: Females are more likely to survive.\n",
    "SibSp/Parch: People traveling alone are more likely to survive.\n",
    "Age: Young children are more likely to survive.\n",
    "Pclass: People of higher socioeconomic class are more likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf22dc",
   "metadata": {},
   "source": [
    "4) Data Visualization\n",
    "It's time to visualize our data so we can see whether our predictions were accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc26773",
   "metadata": {},
   "source": [
    "Sex Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a bar plot of survival by sex\n",
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n",
    "\n",
    "#print percentages of females vs. males that survive\n",
    "print(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cf147",
   "metadata": {},
   "source": [
    "As predicted, females have a much higher chance of survival than males. The Sex feature is essential in our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbde1c2",
   "metadata": {},
   "source": [
    "Pclass Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb31690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a bar plot of survival by Pclass\n",
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n",
    "\n",
    "#print percentage of people by Pclass that survived\n",
    "print(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c61791",
   "metadata": {},
   "source": [
    "As predicted, people with higher socioeconomic class had a higher rate of survival. (62.9% vs. 47.3% vs. 24.2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15d620",
   "metadata": {},
   "source": [
    "SibSp Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80199ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a bar plot for SibSp vs. survival\n",
    "sns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n",
    "\n",
    "#I won't be printing individual percent values for all of these.\n",
    "print(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e88fb",
   "metadata": {},
   "source": [
    "In general, it's clear that people with more siblings or spouses aboard were less likely to survive. However, contrary to expectations, people with no siblings or spouses were less to likely to survive than those with one or two. (34.5% vs 53.4% vs. 46.4%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02935cdc",
   "metadata": {},
   "source": [
    "Parch Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a bar plot for Parch vs. survival\n",
    "sns.barplot(x=\"Parch\", y=\"Survived\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eab109",
   "metadata": {},
   "source": [
    "People with less than four parents or children aboard are more likely to survive than those with four or more. Again, people traveling alone are less likely to survive than those with 1-3 parents or children."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9246205",
   "metadata": {},
   "source": [
    "Age Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408cd60",
   "metadata": {},
   "source": [
    "#sort the ages into logical categories\n",
    "train[\"Age\"] = train[\"Age\"].fillna(-0.5)\n",
    "test[\"Age\"] = test[\"Age\"].fillna(-0.5)\n",
    "bins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\n",
    "labels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\n",
    "test['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n",
    "\n",
    "#draw a bar plot of Age vs. survival\n",
    "sns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68b7d5",
   "metadata": {},
   "source": [
    "Babies are more likely to survive than any other age group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c542ee",
   "metadata": {},
   "source": [
    "Cabin Feature\n",
    "I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\n",
    "test[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n",
    "\n",
    "#calculate percentages of CabinBool vs. survived\n",
    "print(\"Percentage of CabinBool = 1 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 1].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of CabinBool = 0 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 0].value_counts(normalize = True)[1]*100)\n",
    "#draw a bar plot of CabinBool vs. survival\n",
    "sns.barplot(x=\"CabinBool\", y=\"Survived\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a149d",
   "metadata": {},
   "source": [
    "People with a recorded Cabin number are, in fact, more likely to survive. (66.6% vs 29.9%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8eaa6",
   "metadata": {},
   "source": [
    "5) Cleaning Data\n",
    "Time to clean our data to account for missing values and unnecessary information!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379d2b9",
   "metadata": {},
   "source": [
    "Looking at the Test Data\n",
    "Let's see how our test data looks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc8b380",
   "metadata": {},
   "source": [
    "We have a total of 418 passengers.\n",
    "1 value from the Fare feature is missing.\n",
    "Around 20.5% of the Age feature is missing, we will need to fill that in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b3f61",
   "metadata": {},
   "source": [
    "Cabin Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d2df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll start off by dropping the Cabin feature since not a lot more useful information can be extracted from it.\n",
    "train = train.drop(['Cabin'], axis = 1)\n",
    "test = test.drop(['Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1423d",
   "metadata": {},
   "source": [
    "Ticket Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also drop the Ticket feature since it's unlikely to yield any useful information\n",
    "train = train.drop(['Ticket'], axis = 1)\n",
    "test = test.drop(['Ticket'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89121781",
   "metadata": {},
   "source": [
    "Embarked Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd24107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to fill in the missing values in the Embarked feature\n",
    "print(\"Number of people embarking in Southampton (S):\")\n",
    "southampton = train[train[\"Embarked\"] == \"S\"].shape[0]\n",
    "print(southampton)\n",
    "\n",
    "print(\"Number of people embarking in Cherbourg (C):\")\n",
    "cherbourg = train[train[\"Embarked\"] == \"C\"].shape[0]\n",
    "print(cherbourg)\n",
    "\n",
    "print(\"Number of people embarking in Queenstown (Q):\")\n",
    "queenstown = train[train[\"Embarked\"] == \"Q\"].shape[0]\n",
    "print(queenstown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fba08c",
   "metadata": {},
   "source": [
    "It's clear that the majority of people embarked in Southampton (S). Let's go ahead and fill in the missing values with S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the missing values in the Embarked feature with S\n",
    "train = train.fillna({\"Embarked\": \"S\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d83b6",
   "metadata": {},
   "source": [
    "Age Feature\n",
    "Next we'll fill in the missing values in the Age feature. Since a higher percentage of values are missing, it would be illogical to fill all of them with the same value (as we did with Embarked). Instead, let's try to find a way to predict the missing ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a combined group of both datasets\n",
    "combine = [train, test]\n",
    "\n",
    "#extract a title for each Name in the train and test datasets\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3688de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace various titles with more common names\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    \n",
    "    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map each of the title groups to a numerical value\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a424fbd",
   "metadata": {},
   "source": [
    "The code I used above is from here. Next, we'll try to predict the missing Age values from the most common age for their Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea03b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing age with mode age group for each title\n",
    "mr_age = train[train[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\n",
    "miss_age = train[train[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\n",
    "mrs_age = train[train[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\n",
    "master_age = train[train[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\n",
    "royal_age = train[train[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\n",
    "rare_age = train[train[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n",
    "\n",
    "age_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n",
    "\n",
    "#I tried to get this code to work with using .map(), but couldn't.\n",
    "#I've put down a less elegant, temporary solution for now.\n",
    "#train = train.fillna({\"Age\": train[\"Title\"].map(age_title_mapping)})\n",
    "#test = test.fillna({\"Age\": test[\"Title\"].map(age_title_mapping)})\n",
    "\n",
    "for x in range(len(train[\"AgeGroup\"])):\n",
    "    if train[\"AgeGroup\"][x] == \"Unknown\":\n",
    "        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n",
    "        \n",
    "for x in range(len(test[\"AgeGroup\"])):\n",
    "    if test[\"AgeGroup\"][x] == \"Unknown\":\n",
    "        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1728d8",
   "metadata": {},
   "source": [
    "Now that we've filled in the missing values at least somewhat accurately (I will work on a better way for predicting missing age values), it's time to map each age group to a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map each Age value to a numerical value\n",
    "age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n",
    "train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n",
    "test['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n",
    "\n",
    "train.head()\n",
    "\n",
    "#dropping the Age feature for now, might change\n",
    "train = train.drop(['Age'], axis = 1)\n",
    "test = test.drop(['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3fd5f",
   "metadata": {},
   "source": [
    "Name Feature\n",
    "We can drop the name feature now that we've extracted the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a164d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the name feature since it contains no more useful information.\n",
    "train = train.drop(['Name'], axis = 1)\n",
    "test = test.drop(['Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3899081",
   "metadata": {},
   "source": [
    "Sex Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map each Sex value to a numerical value\n",
    "sex_mapping = {\"male\": 0, \"female\": 1}\n",
    "train['Sex'] = train['Sex'].map(sex_mapping)\n",
    "test['Sex'] = test['Sex'].map(sex_mapping)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf553824",
   "metadata": {},
   "source": [
    "Embarked Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650742c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map each Embarked value to a numerical value\n",
    "embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "train['Embarked'] = train['Embarked'].map(embarked_mapping)\n",
    "test['Embarked'] = test['Embarked'].map(embarked_mapping)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e1f4a",
   "metadata": {},
   "source": [
    "Fare Feature\n",
    "It's time separate the fare values into some logical groups as well as filling in the single missing value in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing Fare value in test set based on mean fare for that Pclass \n",
    "for x in range(len(test[\"Fare\"])):\n",
    "    if pd.isnull(test[\"Fare\"][x]):\n",
    "        pclass = test[\"Pclass\"][x] #Pclass = 3\n",
    "        test[\"Fare\"][x] = round(train[train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)\n",
    "        \n",
    "#map Fare values into groups of numerical values\n",
    "train['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\n",
    "test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n",
    "\n",
    "#drop Fare values\n",
    "train = train.drop(['Fare'], axis = 1)\n",
    "test = test.drop(['Fare'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check test data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255cb33",
   "metadata": {},
   "source": [
    "6) Choosing the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569d773",
   "metadata": {},
   "source": [
    "Splitting the Training Data\n",
    "We will use part of our training data (22% in this case) to test the accuracy of our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictors = train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "target = train[\"Survived\"]\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3911e8",
   "metadata": {},
   "source": [
    "Testing Different Models\n",
    "I will be testing the following models with my training data (got the list from here):\n",
    "\n",
    "Gaussian Naive Bayes\n",
    "Logistic Regression\n",
    "Support Vector Machines\n",
    "Perceptron\n",
    "Decision Tree Classifier\n",
    "Random Forest Classifier\n",
    "KNN or k-Nearest Neighbors\n",
    "Stochastic Gradient Descent\n",
    "Gradient Boosting Classifier\n",
    "For each model, we set the model, fit it with 80% of our training data, predict for 20% of the training data and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred = gaussian.predict(x_val)\n",
    "acc_gaussian = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_val)\n",
    "acc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfe82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred = svc.predict(x_val)\n",
    "acc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(x_train, y_train)\n",
    "y_pred = linear_svc.predict(x_val)\n",
    "acc_linear_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d487b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "y_pred = perceptron.predict(x_val)\n",
    "acc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "decisiontree.fit(x_train, y_train)\n",
    "y_pred = decisiontree.predict(x_val)\n",
    "acc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_decisiontree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1686d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred = randomforest.predict(x_val)\n",
    "acc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_randomforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN or k-Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_val)\n",
    "acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "y_pred = sgd.predict(x_val)\n",
    "acc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "gbk = GradientBoostingClassifier()\n",
    "gbk.fit(x_train, y_train)\n",
    "y_pred = gbk.predict(x_val)\n",
    "acc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_gbk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07688acf",
   "metadata": {},
   "source": [
    "Let's compare the accuracies of each model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n",
    "    'Score': [acc_svc, acc_knn, acc_logreg, \n",
    "              acc_randomforest, acc_gaussian, acc_perceptron,acc_linear_svc, acc_decisiontree,\n",
    "              acc_sgd, acc_gbk]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce84b8",
   "metadata": {},
   "source": [
    "I decided to use the Gradient Boosting Classifier model for the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0858f2",
   "metadata": {},
   "source": [
    "7) Creating Submission File\n",
    "It's time to create a submission.csv file to upload to the Kaggle competition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ids as PassengerId and predict survival \n",
    "ids = test['PassengerId']\n",
    "predictions = gbk.predict(test.drop('PassengerId', axis=1))\n",
    "\n",
    "#set the output as a dataframe and convert to csv file named submission.csv\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e670de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7d2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a9ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9149803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
